{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be595afd-c0e5-4632-a54c-4116dbe019f0",
   "metadata": {},
   "source": [
    "DO NOT FORGET TO,\n",
    "- install dependencies both on c++ and python\n",
    "- `pip install -e .` in __./min_flash_attention__ directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105af564-b515-40d7-92e9-cc850df6981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from min_flash_attention import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3416d358-b7f5-4986-aeeb-8513bac8f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use small model params, otherwise slower than manual attention. See caveats in README.\n",
    "batch_size = 8\n",
    "n_head = 12\n",
    "seq_len = 1024\n",
    "head_embd = 64\n",
    "\n",
    "q = torch.randn(batch_size, n_head, seq_len, head_embd, requires_grad=True).cuda()\n",
    "k = torch.randn(batch_size, n_head, seq_len, head_embd, requires_grad=True).cuda()\n",
    "v = torch.randn(batch_size, n_head, seq_len, head_embd, requires_grad=True).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675d4a51-33a6-49b6-8ad8-c810d3dbd729",
   "metadata": {},
   "source": [
    "### Vanilla attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ddeff7-68a8-4a94-81b3-d219b2420d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our minimal flash attention aims to be faster than this by avoiding HBM read/writes of N^2 matrices.\n",
    "def vanilla_attention(q, k, v):\n",
    "    att = (q @ k.transpose(-2, -1) * (1.0 / math.sqrt(k.size(-1))))\n",
    "    # add casual mask\n",
    "    mask = torch.tril(torch.ones(att.size(-2), att.size(-1)), diagonal=0).cuda()\n",
    "    att = att.masked_fill(mask == 0, float('-inf'))\n",
    "    att = F.softmax(att, dim=-1)\n",
    "    y = att @ v\n",
    "    return y\n",
    "\n",
    "with torch.autograd.profiler.profile(use_cuda=True) as prof:\n",
    "    manual_result = vanilla_attention(q, k, v)\n",
    "\n",
    "prof.key_averages().table(sort_by='cuda_time_total', row_limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169b29fa-b8b7-46c6-9c4a-2d94f58879de",
   "metadata": {},
   "source": [
    "### Min Flash attention v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1096dd21-34d6-48a4-ae5e-a32c9ee4fc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (\n",
    "    torch.autograd.profiler.profile(use_cuda=True) as prof,\n",
    "    torch.no_grad(),\n",
    "):\n",
    "    minimal_result, l, m = min_flash_attention.forward(q, k, v, 1)\n",
    "prof.key_averages().table(sort_by='cuda_time_total', row_limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d2e129-3106-4bb6-9954-c33259dadb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention values sanity check\n",
    "torch.allclose(minimal_result, manual_result, rtol=0, atol=1e-03)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f328c6-649d-424f-ad3b-0bfc74db0a31",
   "metadata": {},
   "source": [
    "### Min Flash attention v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5431b3c1-57f8-42d1-aa9b-242bbe0af430",
   "metadata": {},
   "outputs": [],
   "source": [
    "with (\n",
    "    torch.autograd.profiler.profile(use_cuda=True) as prof,\n",
    "    torch.no_grad(),\n",
    "):\n",
    "    minimal_result, l, _ = min_flash_attention.forward(q, k, v, 2)\n",
    "prof.key_averages().table(sort_by='cuda_time_total', row_limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cced7eb-baff-44ab-a06a-3f4587ac2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention values sanity check\n",
    "torch.allclose(minimal_result, manual_result, rtol=0, atol=1e-03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87dd803-41b3-4219-a5a4-d45203c8c19a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
